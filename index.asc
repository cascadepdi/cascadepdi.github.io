:source-highlighter: pygments
:stem:
:stem: asciimath

= PROCESSAMENTO DIGITAL DE IMAGENS

== Unidade 3 - Treinamento Viola-Jones

=== Integrantes do Grupo para o Projeto da Unidade 3:
 
DANIEL HENRIQUE SILVA FERNANDES

LUIZ CARLOS ABBOTT GALVÃO NETO 

=== Pré-requisitos 
OpenCV > 3.0.0 instalados para as linguagens C/C++ e Python

=== Objetivo:
Mostrar as utilizações dos comandos opencv_createsamples, opencv_annotation, opencv_traincascade e opencv_visualisation para treinar o seu próprio arquivo cascade.

=== Descrição dos problemas:
Nesse trabalho definimos dois desafios que serão:

1. Dado uma imagem que contenha o objeto desejado para identificar, gerar varias imagens positivas a partir dela. Essa estrategia é útil para logotipos que não variam muito sua forma. Para essa etapa, o objetivo sera o de identificar o simbolo da Coca-Cola.

2. Fornecer um conjunto de Imagens Positivas para treinar o cascade. Nessa etapa, o objetivo será o de identificar a palma da mão de uma pessoa.

=== Encontrando o Simbolo da Coca-Cola

A imagem tomada como base para é mostrada na Figura 1.

image::exemplos/Unidade3/coke.jpg[Coca-Cola, title = "Imagem Base"]

Em seguida, selecionamos só a área de interesse usando o algoritmo selectarea.cpp

[[exa_selectarea, selectarea]]
[source,cpp]
----
include::exemplos/Unidade3/selectarea.cpp[]
----

Após selecionar nossa região de interesse, nossa imagem ficou como mostrada a seguir na Figura 2.

image::exemplos/Unidade3/coke-resize.jpg[ResizeCoca-Cola.jpg, title = "Coca-Cola_resize.jpg"]

Apesar de ter sido cortada a imagem original, a região de interesse ainda gerou uma imagem com muitos pixeis (1246,402). Com isso com intuito de simplificar o processo de criação do próprio cascade, diminuíu-se em 90% e a imagem foi convertida para tons de cinza. Para isso, foi utilizado o código ResizePositive.py mostrado a seguir.

[[exa_FindCoke, FindCoke]]
[source,python]
----
include::exemplos/Unidade3/ResizePositive.py[]
----

Com isso, a imagem base final para o cascade ficou como mostrado na Figura 3

image::exemplos/Unidade3/coke-gray.jpg[coke-gray.jpg, title = "imagem Base"]

==== Adquirindo imagens Negativas

Para que se possa treinar o cascade usando uma imagem como base, é necessário um conjunto de imagens negativas, tanto para mostrar ao algoritmo o que não procurar, quanto para inserir a figura nessas imagens. 
As figuras usadas como negativas foram obtidas através do link:
http://host.robots.ox.ac.uk/pascal/VOC/voc2007/[http://host.robots.ox.ac.uk/pascal/VOC/voc2007/].

Esse banco de imagens foi armazenado em uma pasta intitulada "Negatives", o passo seguindo foi criar um arquivo "bg.txt" que contivesse um caminho para todas essas imagens. Para criar o arquivo "bg.txt", utilizou-se o algoritmo CountNegatives.py, que além de criar o arquivo, redimensionou as imagens para 4 vezes a imagem base e as pôs tom de cinza.

[[exa_CountNegatives, CountNegatives]]
[source,python]
----
include::exemplos/Unidade3/CountNegatives.py[]
----

O arquivo bg.txt ficou como mostrado abaixo.
 
.bg.txt
,===
include::exemplos/Unidade3/bg2.txt[]
,===

==== Gerando Imagens Positivas com Base nas Negativas

O comando opencv_createsamples permite criar um conjunto de imagens positivas tomando como base o banco de imagens negativas. Além dele uma serie de parâmetros devem ser levados em consideração, tais como:

-img: Imagem de referência.

-bg: Listagem da Localização do conjunto de imagem negativas.

-info: Localização de onde estarão as novas imagens, juntamente do arquivo .dat, que referenciará as imagens positivas.

-maxxangle: Rotação máxima da imagem base em x.

-maxyangle: Rotação máxima da imagem base em y.

-maxzangle: Rotação máxima da imagem base em z.

-num: Número de imagens Negativas.

-w: Largura proporcional da imagem.

-h: Altura proporcional da imagem.

O comando usado para isso pode ser mostrado a seguir:

opencv_createsamples -img coke-gray.jpg -bg bg.txt -info info3/info.dat -maxxangle 0.5 -maxyangle 0.5 -maxzangle 0.5 -num 9963 -w 24 -h 8

Após lançado esse comando, a pasta info/ estará contendo 9963 imagens com o logotipo da Coca-Cola inserido de forma randômica, como mostrado nas Figuras 4 e 5.

image::exemplos/Unidade3/9959_0182_0074_0163_0054.jpg[0045_0126_0047_0314_0104, title = "Imagem positiva 1", 200, 200]

image::exemplos/Unidade3/9961_0229_0036_0201_0067.jpg[0159_0275_0014_0154_0051, title = "Imagem positiva 2", 1000, 1000]

E o arquivo info.dat estará como mostrado a seguir.

==== Criando o arquivo positives.vec

O penultimo passo é criar um arquivo .vec que será usado para o treinamento, basicamente é um arquivo que vai armazenar, assim como o info.dat, a localização das imagens positivas.

Com isso, lançamos o comando:

opencv_createsamples -info info3/info.dat -w 24 -h 8 -num 9963 -vec positives.vec

==== Treinamento

Possuindo o maior número de argumentos possível,o comando opencv_traincascade é onde ocorre o passo final e é a etapa mais desafiadora. Contudo é possível realizar um treinamento com parâmetros aceitáveis.
 
o seguinte número de argumentos:

opencv_traincascade -data data3 -vec positives.vec -bg bg.txt -numPos 5400 -numNeg 2700 -numStages 25 -w 24 -h 8

Onde:

-data: Pasta onde será salvo o arquivo "cascade.xml.

-vec: arquivo .vec criado anteriormente.

-numPos: Número de Amostras positivas usadas por rodada.

-numNeg: Número de amostras negativas usadas por rodada.

-numStages: Número de Estágios ao qual nosso algoritmo vai passar.

-w: Largura usada na Imagem Base.

-h: Altura Usada na Imagem Base.

==== Resultado Final

Após a execução do treinamento, o arquivo "cascade.xml" foi capaz de identificar o logotipo da Coca em varias imagens, como mostrados nas Figuras 6, 7, 8 e 9.

image::exemplos/Unidade3/demo0.jpg[demo0.jpg, title = "Exemplo 1"]
image::exemplos/Unidade3/demo1.jpg[demo1.jpg, title = "Exemplo 2"]
image::exemplos/Unidade3/demo2.jpg[demo2.jpg, title = "Exemplo 3"]
image::exemplos/Unidade3/demo3.jpg[demo3.jpg, title = "Exemplo 4"]

=== Encontrando a palma da mão

Foi utilizado um banco de dados de 3000 fotos que pode encontrado no seguinte link:https://www.mutah.edu.jo/biometrix/hand-images-databases.html[https://www.mutah.edu.jo/biometrix/hand-images-databases.html]

image::figures/Unidade3/hands_database.png[hands_database.png, title = "Banco de mãos"]

Em seguida usou-se a função opencv_annotation.

opencv_annotation --annotations=/path/to/annotations/file.txt --images=/path/to/image/folder/

Onde:

annotations: caminho para o arquivo txt das anotações, onde você deseja armazenar suas anotações, que são então passadas para o parâmetro -info [example - /data/annotations.txt]

-images: caminho para a pasta que contém as imagens com seus objetos [example - / data / testimages /]

Para indicar onde a mão se encontra na imagem (Se tentou fazer com que a anotação ficasse o mais quadrado possível) e salvar as coordenadas como pode ser visto na Figura 11.

image::figures/Unidade3/hand_annotation.png[hand_annotation.png, title = "Opencv_annotation"]

Pressionando c: confirma a anotação, tornando a anotação verde e confirmando que está armazenada.

Pressionando d: exclui a última anotação da lista de anotações (fácil para remover anotações erradas).

Pressionando n: continua para a próxima imagem.

Pressionando ESC: este sairá do software de anotação.

Então gerou-se o seguinte arquivo txt com as coordenadas de cada mão nas imagens.

image::figures/Unidade3/annotations_text.png[annotations_text.png, title = "Localização das mãos"]
.=
A partir desse arquivo txt foi gerado um arquvio .dat com a localização das mãos.

.info.dat
,===
include::exemplos/Unidade3/info.dat[]
,===

==== Adquirindo imagens Negativas

Não seria ideal utilizar o mesmo banco de dados de imagens negativas do findcoke pois poderia haver mãos nas imagens, então foram procuradas imagens que não teriam mãos e optou-se por usar um banco de imagens de árvores que pode ser encontrado no seguinte link http://www.image-net.org[http://www.image-net.org/]

Esse banco de imagens foi armazenado em uma pasta intitulada "Negatives", o passo seguindo foi criar um arquivo "bg.txt" que contivesse um caminho para todas essas imagens. Para criar o arquivo "bg.txt" utilizou-se o algoritmo CountNegatives.

[[CountNegatives, CountNegatives]]
[source,python]
----
include::exemplos/Unidade3/2-CountNegatives.py[]
----

O arquivo bg.txt ficou da seguinte forma .

.bg.txt
,===
include::exemplos/Unidade3/bg.txt[]
,===

==== Criando o arquivo positives.vec

O penultimo passo é criar um arquivo .vec que será usado para o treinamento, basicamente é um arquivo que vai armazenar, assim como o info.dat, a localização das imagens positivas.

Com isso, foi chamado o comando:

opencv_createsamples -info info/info.dat -w 24 -h 24 -num 1287 -vec positives.vec

==== Treinamento

Foi utilizado novamente o commando opencv_traincascade com os seguintes parâmetros para obter o arquivo cascade.xml

opencv_traincascade -data data -vec positives.vec -bg bg.txt -numPos 1000 -numNeg 1000 -numStages 25 -w 24 -h 24

Onde:

-data: Pasta onde será salvo o arquivo "cascade.xml".

-vec: arquivo .vec criado anteriormente.

-numPos: Número de Amostras positivas usadas por rodada.

-numNeg: Número de amostras negativas usadas por rodada.

-numStages: Número de Estágios ao qual nosso algoritmo vai passar.

-w: Largura usada na Imagem Base.

-h: Altura Usada na Imagem Base.

Na imagem abaixo vê-se o comando em execução

image::figures/Unidade3/inicio.png[inicio.png, title = "Cascade Inicial"]

image::figures/Unidade3/meio.png[meio.png, title = "Cascade em Execução"]

É possível também carregar novos estágios a partir de outros já carregados, é possível notar isso na figura Figura 15.

image::figures/Unidade3/loaded.png[loaded.png, title = "Cascade Final"]

=== Resultado Final

Após gerar o cascade do findcoke e do findhand, a partir do código abaixo foram gravados alguns videos do funcionamento de ambos os cascades em tempo real.

[[VideoWritter, videowriter_basic]]
[source,cpp]
----
include::exemplos/Unidade3/videowriter_basic.cpp[]
----

É possível notar que os parâmetros para o cascade do findcoke foram bem diferentes do findhand.

O resultado obtido pode ser visto nos videos abaixo.

video::exemplos/Unidade3/live2.mp4[width=960, start=0, end=140]

video::exemplos/Unidade3/live1.mp4[width=960, start=0, end=140]


=== Referências

https://docs.opencv.org/3.4/dc/d88/tutorial_traincascade.html[https://docs.opencv.org/3.4/dc/d88/tutorial_traincascade.html]
