= PROCESSAMENTO DIGITAL DE IMAGENS

== Unidade 3 - Treinamento Viola-Jones

=== Integrantes do Grupo para o Projeto da Unidade 3:
 
DANIEL HENRIQUE SILVA FERNANDES

LUIZ CARLOS ABBOTT GALVÃO NETO 

=== Pré-requisitos 
OpenCV > 3.0.0 instalados para as linguagens C/C++ e Python

=== Objetivo:
Mostrar as utilizações dos comandos opencv_createsamples, opencv_annotation, opencv_traincascade e opencv_visualisation para treinar o seu próprio arquivo cascade

=== Descrição dos problemas:
Nesse trabalho definimos dois desafios que serão:

1. Dado uma imagem que contenha o objeto desejado para identificar, gerar varias imagens positivas a partir dela. Essa estrategia é útil para logotipos que não variam muito sua forma. Para essa etapa, o objetivo sera o de identificar o simbolo da Coca-Cola

2. Fornecer um conjunto de Imagens Positivas para treinar o cascade. Nessa etapa, o objetivo será o de identificar a palma da mão de uma pessoa

=== Encontrando o Simbolo da Coca-Cola

A imagem tomada como base para é mostrada na Figura 11

[.text-center]
image::exemplos/Unidade3/coke.jpg[Coca-Cola, title = "Imagem Base"]

Em seguida, selecionamos só a área de interesse usando o algoritmo selectarea.cpp 

[[exa_selectarea, selectarea]]
[source,cpp]
----
include::exemplos/Unidade3/selectarea.cpp[]
----

Após selecionar nossa região de interesse, nossa imagem ficou como mostrada a seguir:

[.text-center]
image::exemplos/Unidade3/coke-resize.jpg[ResizeCoca-Cola.jpg, title = "Coca-Cola_resize.jpg"]

Apesar de termos cortado a imagem original, nossa região de interesse ainda gerou uma imagem com muitos pixeis (1246,402). Com isso com intuito de simplificar o processo de criação do nosso próprio cascade, diminuímos 90% e convertemos a imagem para tons de cinza. Para isso, usamos o código ResizePositive.py mostrado a seguir

[[exa_FindCoke, FindCoke]]
[source,python]
----
include::exemplos/Unidade3/ResizePositive.py[]
----

Com isso, nossa imagem base final para o cascade ficou como:
[.text-center]
image::exemplos/Unidade3/coke-gray.jpg[coke-gray.jpg, title = "imagem Base"]

==== Adquirindo imagens Negativas

Para que se possa treinar o cascade usando uma imagem como base, é necessário um conjunto de imagens negativas, tanto para mostrar ao algoritmo o que não procurar, quanto para inserir a figura nessas imagens. 
As figuras usadas como negativas foram obtidas através do link:
http://host.robots.ox.ac.uk/pascal/VOC/voc2007/[http://host.robots.ox.ac.uk/pascal/VOC/voc2007/]

Esse banco de imagens foi armazenado em uma pasta intitulada "Negatives", o passo seguindo foi criar um arquivo "bg.txt" que contivesse um caminho para todas essas imagens. Para criar o arquivo "bg.txt", usamos o algoritmo CountNegatives.py, que além de criar o arquivo, redimensionou as imagens para 4 vezes a imagem base e as pôs tom de cinza

[[exa_CountNegatives, CountNegatives]]
[source,python]
----
include::exemplos/Unidade3/CountNegatives.py[]
----

Nosso arquivo bg.txt fica como 
.bg.txt
,===
include::exemplos/Unidade3/bg2.txt[]
,===

==== Gerando Imagens Positivas com Base nas Negativas

O comando opencv_createsamples permite criar um conjunto de imagens positivas tomando como base o banco de imagens negativas. Além dele uma serie de parâmetros devem ser levados em consideração, tais como:

Onde:

-img: Imagem de referência

-bg: Listagem da Localização do conjunto de imagem negativas

-info: Localização de onde estarão as novas imagens, juntamente do arquivo .dat, que referenciará as imagens positivas

-maxxangle: Rotação máxima da imagem base em x

-maxyangle: Rotação máxima da imagem base em y

-maxzangle: Rotação máxima da imagem base em z

-num: Número de imagens Negativas

-w: Largura proporcional da imagem

-h: Altura proporcional da imagem

O comando usado para isso pode ser mostrado a seguir:

opencv_createsamples -img coke-gray.jpg -bg bg.txt -info info3/info.dat -maxxangle 0.5 -maxyangle 0.5 -maxzangle 0.5 -num 9963 -w 24 -h 8

Após lançado esse comando, a pasta info/ estará contendo 9963 imagens com o logotipo da Coca-Cola inserido de forma randômica, como mostrado nas imagens a seguir:

[.text-center]
image::exemplos/Unidade3/9959_0182_0074_0163_0054.jpg[0045_0126_0047_0314_0104, title = "Imagem positiva 1"]

[.text-center]
image::exemplos/Unidade3/9961_0229_0036_0201_0067.jpg[0159_0275_0014_0154_0051, title = "Imagem positiva 2"]

E o arquivo info.dat estará como



==== Criando o arquivo positives.vec

O penultimo passo é criar um arquivo .vec que será usado para o treinamento, basicamente é um arquivo que vai armazenar, assim como o info.dat, a localização das imagens positivas

Com isso, lançamos o comando:

opencv_createsamples -info info3/info.dat -w 24 -h 8 -num 9963 -vec positives.vec

==== Treinamento

Possuindo o maior número de argumentos possível,o comando opencv_traincascade é onde ocorre o passo final e é a etapa mais desafiadora. Contudo é possível realizar um treinamento com parâmetros aceitáveis 
o seguinte número de argumentos:

opencv_traincascade -data data3 -vec positives.vec -bg bg.txt -numPos 5400 -numNeg 2700 -numStages 25 -w 24 -h 8

Onde:

-data: Pasta onde será salvo o arquivo "cascade.xml"

-vec: arquivo .vec criado anteriormente

-numPos: Número de Amostras positivas usadas por rodada

-numNeg: Número de amostras negativas usadas por rodada

-numStages: Número de Estágios ao qual nosso algoritmo vai passar

-w: Largura usada na Imagem Base

-h: Altura Usada na Imagem Base

==== Resultado Final

Após a execução do treinamento, nosso arquivo "cascade.xml" foi capaz de identificar o logotipo da Coca em varias imagens, como mostrados a seguir:

[.text-center]
image::exemplos/Unidade3/demo0.jpg[demo0.jpg, title = "Exemplo 1"]
[.text-center]
image::exemplos/Unidade3/demo1.jpg[demo1.jpg, title = "Exemplo 2"]
[.text-center]
image::exemplos/Unidade3/demo2.jpg[demo2.jpg, title = "Exemplo 3"]
[.text-center]
image::exemplos/Unidade3/demo3.jpg[demo3.jpg, title = "Exemplo 4"]

=== Encontrando a palma da mão direita

Utilizamos um banco de dados de 3000 fotos que pode encontrado no seguinte link:https://www.mutah.edu.jo/biometrix/hand-images-databases.html[https://www.mutah.edu.jo/biometrix/hand-images-databases.html]

[.text-center]
image::figures/Unidade3/hands_database.png[hands_database.png, title = "Banco de mãos"]

Em seguida utilizamos a função opencv_annotation 

opencv_annotation --annotations=/path/to/annotations/file.txt --images=/path/to/image/folder/

annotations: caminho para o arquivo txt das anotações, onde você deseja armazenar suas anotações, que são então passadas para o parâmetro -info [example - /data/annotations.txt]

-images: caminho para a pasta que contém as imagens com seus objetos [example - / data / testimages /]

para indicar onde a mão se encontra na imagem (tentou-se fazer com que a anotação ficasse o mais quadrado possível) e salvar as coordenadas como pode ser visto na seguinte imagem

[.text-center]
image::figures/Unidade3/hand_annotation.png[hand_annotation.png, title = "Opencv_annotation"]

Pressionando c: confirma a anotação, tornando a anotação verde e confirmando que está armazenada
Pressionando d: exclui a última anotação da lista de anotações (fácil para remover anotações erradas)
Pressionando n: continua para a próxima imagem
Pressionando ESC: este sairá do software de anotação

Geramos o seguinte arquivo txt com as coordenadas de cada mão nas imagens

[.text-center]
image::figures/Unidade3/annotations_text.png[annotations_text.png, title = "Localização das mãos"]

A partir desse arquivo txt nós geramos um arquvio .dat com a localização das mãos

.info.dat
,===
include::exemplos/Unidade3/info.dat[]
,===

==== Adquirindo imagens Negativas

Não poderiamos utilizar o mesmo banco de dados de imagens negativas do findcoke, então procuramos por imagens que não teriam mãos e chegamos a conclusão de usar um banco de imagens de árvores

Esse banco de imagens foi armazenado em uma pasta intitulada "Negatives", o passo seguindo foi criar um arquivo "bg.txt" que contivesse um caminho para todas essas imagens. Para criar o arquivo "bg.txt" usamos o algoritmo CountNegatives

[[CountNegatives, CountNegatives]]
[source,python]
----
include::exemplos/Unidade3/2-CountNegatives.py[]
----

Nosso arquivo bg.txt ficou da seguinte forma 
.bg.txt
,===
include::exemplos/Unidade3/bg.txt[]
,===

==== Criando o arquivo positives.vec

O penultimo passo é criar um arquivo .vec que será usado para o treinamento, basicamente é um arquivo que vai armazenar, assim como o info.dat, a localização das imagens positivas

Com isso, lançamos o comando:

opencv_createsamples -info info/info.dat -w 24 -h 24 -num 1287 -vec positives.vec

==== Treinamento

Utilizamos novamente o commando opencv_traincascade com os seguintes parâmetros para obter nosso arquivo cascade.xml

opencv_traincascade -data data -vec positives.vec -bg bg.txt -numPos 2500 -numNeg 1250 -numStages 25 -w 24 -h 24

Onde:

-data: Pasta onde será salvo o arquivo "cascade.xml"

-vec: arquivo .vec criado anteriormente

-numPos: Número de Amostras positivas usadas por rodada

-numNeg: Número de amostras negativas usadas por rodada

-numStages: Número de Estágios ao qual nosso algoritmo vai passar

-w: Largura usada na Imagem Base

-h: Altura Usada na Imagem Base

Na imagem abaixo vemos o comando em execução

[.text-center]
image::figures/Unidade3/inicio.png[inicio.png, title = "Cascade Inicial"]

[.text-center]
image::figures/Unidade3/meio.png[meio.png, title = "Cascade em Execução"]

É possível também carregar novos estágios a partir de outros já carregados, vemos isso na figura abaixo

[.text-center]
image::figures/Unidade3/loaded.png[loaded.png, title = "Cascade Final"]

=== Resultado Final

Após gerar o cascade do findcoke e do findhand, a partir do código abaixo nós gravamos alguns videos do funcionamento de ambos os cascades em tempo real

[[VideoWritter, videowriter_basic]]
[source,cpp]
----
include::exemplos/Unidade3/videowriter_basic.cpp[]
----

E o resultado que obtemos foram os videos abaixo

video::exemplos/Unidade3/live2.mp4[width=960, start=0, end=140]

video::exemplos/Unidade3/live1.mp4[width=960, start=0, end=140]


=== Referências

https://docs.opencv.org/3.4/dc/d88/tutorial_traincascade.html[https://docs.opencv.org/3.4/dc/d88/tutorial_traincascade.html]


















































